# Building a Facial Features engine

[badge/API/Yes/green]
[badge/Search/Yes/green]
[badge/UI/Yes/green]

The facial features engines accepts as input a set of face landmarks and associated timestamps, along with an audio input
and its associated timestamp. It computes the correlation between the movement of the face landmarks and the audio. It is
expected that for an actual person, the correlation between the face landmarks and the audio is close to 1.0.

## Engine Manifest

<!-- TODO

All facial features engines should specify the following parameters in their build manifest:

| Parameter | Value |
| --------- | ----- |
| `TODO` | `TODO` |
| `TODO` | `TODO` |

Here is a minimal example `manifest.json` that could apply to a face verification engine:
-->

<!--TODO: Define [](manifest.example.json ':include :type=code json')-->

See the full documentation for [engine manifest standards](/developer/engines/standards/engine-manifest/) for more details.

<!-- TODO ## Engine Input -->

<!-- TODO -->

### Training and Libraries

No training is required for the facial features engine.

## Engine Input

The facial features engine performs [segment processing](/developer/engines/processing-modes/segment-processing/).

It accepts as input a custom binary file containing the following in the respective order:

    1. 8 bytes containing the number of bytes of a byte-encrypted json string
    2. A byte-encrypted JSON string
    3. 8 bytes containing the number of bytes of a binary audio file
    4. Binary audio file

Note: An example of the byte-encrypted JSON string is as follows:

    {
        "faceLandmarks": <an array of 68-point face landmark objects generated by face-api.js>,
        "faceTimes": <an array containing the millisecond timestamp of each face landmark object>,
        "voiceStartTime": <the millisecond timestamp of the beginning of the audio file>
    }

## Engine Output

The facial features engine output should be stored as an `object` in the [vtn-standard](/developer/engines/standards/engine-output/).
The `type` of the object is `facial-features`. Each face maps back to a specified user identity which corresponds to an entity in a library;
hence the object includes the `entityId` along with the `libraryId`. The similarity score of the face to the face(s) for
the entity is the `confidence`. The `mode` specifies whether the engine is run in `enroll` or `verify` mode.

### Example

Here is an example of the simplest type of face verification engine output:

[](vtn-standard.example.json ':include :type=code json')
